DynamicDistributionUtils.monitor.userCancel=\u7528\u6237\u5DF2\u53D6\u6D88\u3002
DynamicDistributionUtils.check.sparkVersion.unsupport=\u4E0D\u652F\u6301 Spark \u7248\u672C: {0}\u3002
DynamicModuleAdapter.monitor.buildModule=\u6B63\u5728\u91C7\u96C6 {0} \u7684\u4F9D\u8D56\u5173\u7CFB\uFF0Cmvn uri\uFF1A{1}
DynamicModuleAdapter.exception.exclusion.unsupport=\u4E0D\u652F\u6301\u4E3A {0} \u6DFB\u52A0\u6392\u9664\u9879\uFF0C\u76EE\u524D\u4EC5\u652F\u6301 BASE \u7C7B\u578B
DynamicModuleAdapter.exception.reference.notFound=\u627E\u4E0D\u5230\u5DF2\u5B58\u5728\u7684\u5E93\uFF1A{0}
DynamicModuleAdapter.exception.version.notFound=\u65E0\u6CD5\u4E3A {1}:{2} \u627E\u5230 {0} \u7684\u5BF9\u5E94\u7248\u672C
DynamicModuleAdapter.exception.wrongConfig={0} \u7684\u6A21\u677F\u914D\u7F6E\u4E0D\u6B63\u786E\uFF0C\u8BF7\u68C0\u67E5\u3002
DynamicModuleGroupAdapter.monitor.buildModuleGroup=\u6B63\u5728\u4E3A {0} \u751F\u6210\u6A21\u5757\u7EC4
DynamicModuleGroupAdapter.exception.noModuleAdapterFound=\u5728 {1} \u4E2D\u91C7\u96C6 {0} \u7684\u4F9D\u8D56\u5173\u7CFB\u65F6\u51FA\u9519
DynamicDistriConfigAdapter.diffDistri=\u4E0D\u540C\u5206\u5E03\uFF1A{0} <> {1}
DynamicClassloaderAdapter.exception.noModuleAdapterFound=\u627E\u4E0D\u5230 id \u4E3A {0} \u7684\u6A21\u5757\u7EC4\uFF0C\u5982\u679C\u4E0D\u662F\u9519\u8BEF\uFF0C\u8BF7\u68C0\u67E5 {1}
DynamicClassloaderAdapter.monitor.buildClassLoader=\u6B63\u5728\u4E3A {0} \u751F\u6210\u7C7B\u52A0\u8F7D\u5668
DynamicDistribution.name.project={0} [{1}]
DynamicDistribution.name.builtin={0} [\u5185\u7F6E]
DynamicDistribution.name.current=\u5F53\u524D\u5DE5\u7A0B
DynamicLibraryNeededExtensionAdaper.monitor.waitAllFinish=\u7B49\u5F85 {0} \u5B50\u4EFB\u52A1\u5B8C\u6210...
EDatabriksCloudProvider.AWS=AWS
EDatabriksCloudProvider.Azure=Azure
EDatabriksCloudProvider.GCP=GCP
EDatabriksSubmitMode.CREATE_RUN_JOB=\u7ACB\u5373\u521B\u5EFA\u5E76\u8FD0\u884C
EDatabriksSubmitMode.RUN_SUBMIT=\u63D0\u4EA4\u8FD0\u884C
ESparkMode.CLUSTER=\u72EC\u7ACB
ESparkMode.YARN_CLIENT=Yarn \u5BA2\u6237\u7AEF
ESparkMode.YARN_CLUSTER=Yarn \u96C6\u7FA4
ESparkMode.KUBERNETES=Kubernetes
ESparkMode.SPARK_LOCAL=\u672C\u5730
ESparkMode.CDE=Cloudera \u6570\u636E\u5DE5\u7A0B
ESparkMode.DATAPROC=Dataproc
EDataprocAuthType.OAUTH_API=OAuth2 \u8BBF\u95EE\u4EE4\u724C
EDataprocAuthType.SERVICE_ACCOUNT=\u670D\u52A1\u5E10\u6237
ESparkMode.DATABRICKS=Databricks
ESparkMode.STANDALONE=\u72EC\u7ACB
DISTRIBUTION.NAME=\u53D1\u884C\u7248
SPARK_VERSION.NAME=\u7248\u672C
SUPPORTED_SPARK_VERSION.NAME=Spark \u7248\u672C
SPARK_MODE.NAME=\u8FD0\u884C\u65F6\u6A21\u5F0F/\u73AF\u5883
DATABRICKS_RUNTIME_VERSION.NAME=Runtime \u7248\u672C
IMPALA_VERSION.NAME=\u7248\u672C
HBASE_VERSION.NAME=HBase \u7248\u672C
HIVE_VERSION.NAME=Hive \u7248\u672C
DB_VERSION.NAME=\u7248\u672C
