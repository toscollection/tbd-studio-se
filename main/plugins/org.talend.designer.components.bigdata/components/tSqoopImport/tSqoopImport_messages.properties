HELP=org.talend.help.tSqoopImport

JDBC_PROPERTY.NAME=JDBC Property
HADOOP_PROPERTY.NAME=Hadoop Property

LONG_NAME=Imports an individual table from an RDBMS to HDFS
EXTERNAL.NAME=Sqoop Import
TEMPFILE.NAME=Temp data directory path

COMMON_SQOOP_OPTIONS.NAME=Common arguments

CONNECTION.NAME=Connection
TABLE.NAME=Table Name
USERNAME.NAME=Username
PASSWORD_STORED_IN_FILE.NAME=The password is stored in a file
PASSWORD_FILE.NAME=File path
PASSWORD.NAME=Password
DRIVER_JAR.NAME=Driver JAR
DRIVER_JAR.ITEM.JAR_NAME=Jar name
DRIVER_CLASS.NAME=Class name

USE_COLUMNS.NAME=Specify Columns
COLUMNS.NAME=Columns
COLUMNS.ITEM.COLUMN=Column
USE_WHERE.NAME=Use WHERE clause
WHERE.NAME=
PRINT_LOG.NAME=Print Log
VERBOSE.NAME=Verbose
USE_MAPPERS.NAME=Specify Number of Mappers
MAPPERS.NAME=
USE_TARGET.NAME=Specify Target Dir
TARGET.NAME=
APPEND.NAME=Append data to an existing dataset in HDFS

DIRECT.NAME=Use direct import fast path
DEFINE_DIRECT_SPLIT_SIZE.NAME=Split the input stream every N bytes
DIRECT_SPLIT_SIZE.NAME=

COMPRESS.NAME=Enable compression
DEFINE_HADOOP_CODEC.NAME=Use Hadoop codec
HADOOP_CODEC.NAME=

DELETE_TARGET_DIR.NAME=Delete target directory
FILE_FORMAT.NAME=File Format
FILE_FORMAT.ITEM.textfile=Text file
FILE_FORMAT.ITEM.sequencefile=Sequence file
FILE_FORMAT.ITEM.avrofile=Avro file
MYSQL_DELIMITERS.NAME=Use MySQL default Delimiters

ADDITIONAL.NAME=Additional Arguments
ADDITIONAL_ARGUMENTS.NAME=
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_VALUE=Value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--bindir=--bindir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--boundary-query=--boundary-query
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--class-name=--class-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--column-family=--column-family
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--connection-manager=--connection-manager
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hcatalog-table=--create-hcatalog-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--create-hive-table=--create-hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--driver=--driver
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--direct-split-size=--direct-split-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--enclosed-by=--enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--escaped-by=--escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fetch-size=--fetch-size
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--fields-terminated-by=--fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-mapred-home=--hadoop-mapred-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hadoop-home=--hadoop-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-create-table=--hbase-create-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-row-key=--hbase-row-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hbase-table=--hbase-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-database=--hcatalog-database
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-home=--hcatalog-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-storage-stanza=--hcatalog-storage-stanza
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hcatalog-table=--hcatalog-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-delims-replacement=--hive-delims-replacement
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-drop-import-delims=--hive-drop-import-delims
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-home=--hive-home
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-import=--hive-import
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-overwrite=--hive-overwrite
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-key=--hive-partition-key
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-partition-value=--hive-partition-value
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--hive-table=--hive-table
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--inline-lob-limit=--inline-lob-limit
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-enclosed-by=--input-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-escaped-by=--input-escaped-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-fields-terminated-by=--input-fields-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-lines-terminated-by=--input-lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--input-optionally-enclosed-by=--input-optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--jar-file=--jar-file
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--lines-terminated-by=--lines-terminated-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--null-non-string=--null-non-string
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--null-string=--null-string
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--optionally-enclosed-by=--optionally-enclosed-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--outdir=--outdir
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--package-name=--package-name
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--split-by=--split-by
ADDITIONAL_ARGUMENTS.ITEM.ADDITIONAL_ARGUMENT.ITEM.--warehouse-dir=--warehouse-dir

ADDITIONAL_COMMANDLINE_ARGUMENTS.NAME=

ADDITIONAL_JAVA.NAME=Additional Arguments
ADDITIONAL_JAVA.ITEM.ADDITIONAL_ARGUMENT=Argument
ADDITIONAL_JAVA.ITEM.ADDITIONAL_VALUE=Value

TYPE_MAPPING.NAME=Type mapping
DEFINE_JAVA_MAPPING.NAME=Define Java mapping
JAVA_TYPE_MAPPING.NAME=Java mapping
JAVA_TYPE_MAPPING.ITEM.COLUMN_NAME=Column name
JAVA_TYPE_MAPPING.ITEM.JAVA_TYPE=Java type

DEFINE_HIVE_MAPPING.NAME=Define Hive mapping
HIVE_TYPE_MAPPING.NAME=Hive mapping
HIVE_TYPE_MAPPING.ITEM.COLUMN_NAME=Column name
HIVE_TYPE_MAPPING.ITEM.HIVE_TYPE=Hive type

OUTPUT_MESSAGE.NAME=Output Message

CONTROL_SQOOP_OPTIONS.NAME=Import control arguments

USE_QUERY.NAME=Use query
QUERY.NAME=Query

USE_SPLIT.NAME=Specify Split By
SPLIT.NAME=

MODE.NAME=Mode
USE_COMMANDLINE.NAME=Use Commandline
USE_JAVAAPI.NAME=Use Java API

VERSION.NAME=Version

DISTRIBUTION.NAME=Distribution
DISTRIBUTION.ITEM.HORTONWORKS=HortonWorks
DISTRIBUTION.ITEM.CLOUDERA=Cloudera
DISTRIBUTION.ITEM.MAPR=MapR
DISTRIBUTION.ITEM.AMAZON_EMR=Amazon EMR
DISTRIBUTION.ITEM.PIVOTAL_HD=Pivotal HD
DISTRIBUTION.ITEM.CUSTOM=Custom - Unsupported

DB_VERSION.NAME=Hadoop version
DB_VERSION.ITEM.Cloudera_CDH3=Cloudera CDH3 (Deprecated)
DB_VERSION.ITEM.MAPR1=MapR 1.2.0 (Sqoop 1.3) (Deprecated)
DB_VERSION.ITEM.MAPR2=MapR 2.0.0 (Sqoop 1.4)
DB_VERSION.ITEM.MAPR212=MapR 2.1.2 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR213=MapR 2.1.3 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR301=MapR 3.0.1 (Sqoop 1.4.2)
DB_VERSION.ITEM.MAPR310=MapR 3.1.0
DB_VERSION.ITEM.MAPR401=MapR 4.0.1(YARN mode)
DB_VERSION.ITEM.HDP_1_0=Hortonworks Data Platform V1.0.0 (Deprecated)
DB_VERSION.ITEM.HDP_1_2=Hortonworks Data Platform V1.2.0(Bimota)
DB_VERSION.ITEM.HDP_1_3=Hortonworks Data Platform V1.3.0(Condor)
DB_VERSION.ITEM.HDP_2_0=Hortonworks Data Platform V2.0.0(BigWheel)
DB_VERSION.ITEM.HDP_2_1=Hortonworks Data Platform V2.1.0(Baikal)
DB_VERSION.ITEM.HDP_2_2=Hortonworks Data Platform V2.2.0
DB_VERSION.ITEM.Cloudera_CDH4=Cloudera CDH4.X (MR 1 mode)
DB_VERSION.ITEM.Cloudera_CDH4_YARN=Cloudera CDH4.3+(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5=Cloudera CDH5.0(YARN mode)
DB_VERSION.ITEM.Cloudera_CDH5_1_MR1=Cloudera CDH5.1(MR 1 mode)
DB_VERSION.ITEM.Cloudera_CDH5_1=Cloudera CDH5.1(YARN mode)
DB_VERSION.ITEM.PIVOTAL_HD_1_0_1=Pivotal HD 1.0.1
DB_VERSION.ITEM.PIVOTAL_HD_2_0=Pivotal HD 2.0
DB_VERSION.ITEM.APACHE_2_4_0_EMR=Apache 2.4.0

USE_DATANODE_HOSTNAME.NAME=Use Datanode Hostname

FS_DEFAULT_NAME.NAME=NameNode URI
MAPRED_JOB_TRACKER.NAME=JobTracker Host

USE_KRB.NAME=Use kerberos authentication
NAMENODE_PRINCIPAL.NAME=Namenode principal
JOBTRACKER_PRINCIPAL.NAME=JobTracker principal
RESOURCEMANAGER_PRINCIPAL.NAME=Resource manager principal
JOBHISTORY_PRINCIPAL.NAME=Job history principal
USE_KEYTAB.NAME=Use a keytab to authenticate
PRINCIPAL.NAME=Principal
KEYTAB_PATH.NAME=Keytab
AUTHENTICATION.NAME=Authentication

CONFIGURATION.NAME=Configuration

USE_SPEED_PARALLEL.NAME=Use speed parallel data transfers
SPECIFIC_PARAMS.NAME=Specific params
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM=Argument

SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-batch-size=teradata.db.input.batch.size
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-file-format=teradata.db.input.file.format
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-job-type=teradata.db.input.job.type
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-method=teradata.db.input.method
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-num-mappers=teradata.db.input.num.mappers
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-num-partitions-in-staging=teradata.db.input.num.partitions.in.staging
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-partition-num=teradata.db.input.partition.num
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-separator=teradata.db.input.separator
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-count-query=teradata.db.input.source.count.query
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-field-names=teradata.db.input.source.field.names
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-query=teradata.db.input.source.query
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-source-table=teradata.db.input.source.table
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-split-by-column=teradata.db.input.split.by.column
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-force=teradata.db.input.stage.force
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-database=teradata.db.input.stage.database
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-stage-table-name=teradata.db.input.stage.table.name
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-database=teradata.db.input.target.database
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-field-names=teradata.db.input.target.field.names
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-partition-schema=teradata.db.input.target.partition.schema
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-table=teradata.db.input.target.table
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-table-schema=teradata.db.input.target.table.schema
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-target-paths=teradata.db.input.target.paths
SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM.ITEM.teradata-db-input-teradata-db-hive-configuration-file=teradata.db.input.teradata.db.hive.configuration.file

SPECIFIC_PARAMS.ITEM.SPECIFIC_PARAM_VALUE=Value
SPEED_PARALLEL.NAME=Connector specific configuration
USE_ADDITION_PARAM.NAME=Use additional params
SPECIFIC_ADDITION_PARAM.NAME=Specific additional params

HADOOP_ADVANCED_PROPERTIES.NAME=Hadoop Properties 
HADOOP_ADVANCED_PROPERTIES.ITEM.PROPERTY=Property
HADOOP_ADVANCED_PROPERTIES.ITEM.VALUE=Value

USE_YARN.NAME=Use Yarn
RESOURCE_MANAGER.NAME=Resource Manager
SET_JOBHISTORY_ADDRESS.NAME=Set jobhistory address
JOBHISTORY_ADDRESS.NAME=
CLASSPATH_SEPARATOR.NAME=Path separator in server

MEMORY_PARAMETERS.NAME=Job memory parameters
MAPRED_JOB_MAP_MEMORY_MB.NAME = Map (in Mb)
MAPRED_JOB_REDUCE_MEMORY_MB.NAME = Reduce (in Mb)

SET_SCHEDULER_ADDRESS.NAME=Set resourcemanager scheduler address
RESOURCEMANAGER_SCHEDULER_ADDRESS.NAME=
SET_STAGING_DIRECTORY.NAME=Set staging directory
STAGING_DIRECTORY.NAME=
SET_MEMORY.NAME=Set memory
MAPREDUCE_MAP_MEMORY_MB.NAME= Map (in Mb)
MAPREDUCE_REDUCE_MEMORY_MB.NAME= Reduce (in Mb)
YARN_APP_MAPREDUCE_AM_RESOURCE_MB.NAME= ApplicationMaster (in Mb)

HADOOP_USER.NAME=Hadoop user name

CROSS_PLATFORM_SUBMISSION.NAME=Activate the cross platform application submission

DIE_ON_ERROR.NAME=Die on error

EXIT_CODE.NAME=Exit code
