<%@ jet
imports="
        org.talend.designer.codegen.config.CodeGeneratorArgument
        org.talend.core.model.process.INode
        org.talend.core.model.process.ElementParameterParser
        org.talend.core.model.metadata.IMetadataTable
        org.talend.core.model.metadata.IMetadataColumn
        org.talend.core.model.process.IConnection
        org.talend.designer.runprocess.ProcessorException
        org.talend.designer.runprocess.ProcessorUtilities

        java.util.List
        java.util.Map
"
%>

<%
    CodeGeneratorArgument codeGenArgument = (CodeGeneratorArgument) argument;
    INode node = (INode)codeGenArgument.getArgument();

    String cid = node.getUniqueName();
    String processId = node.getProcess().getId();

    boolean isLog4jEnabled = ("true").equals(ElementParameterParser.getValue(node.getProcess(), "__LOG4J_ACTIVATE__"));

    String dbtable = null;
    String uniqueNameConnection = null;
    INode previousNode = null;
    boolean isExecutedThroughWebHCat = false;
    boolean setFsDefaultName=false;
    String connectionMode = "";
    String fsDefaultName = "";

    %>
    String select_query_<%=cid %> = null;
    String tableName_<%=cid%> = null;
    <%
    List<IConnection> connections = (List<IConnection>) node.getIncomingConnections();
    if(connections != null && connections.size() > 0 && connections.get(0) != null) {
        IConnection connection = connections.get(0);
        previousNode = connection.getSource();
        String previousComponentName = previousNode.getUniqueName();
        dbtable = connection.getName();
        uniqueNameConnection = connection.getUniqueName();

        %>
        select_query_<%=cid %> = (String) globalMap.get("<%=previousComponentName%>"+"QUERY"+"<%=uniqueNameConnection%>");

        <%
    }

    String differenttable = ElementParameterParser.getValue(node, "__DIFFERENT_TABLE_NAME__");
    boolean useDifferentTable = "true".equals(ElementParameterParser.getValue(node, "__USE_DIFFERENT_TABLE__"));

       String dbschema = ElementParameterParser.getValue(node,"__ELT_SCHEMA_NAME__");
    %>
        String dbschema_<%=cid%> = <%=dbschema%>;
        if(dbschema_<%=cid%> != null && dbschema_<%=cid%>.trim().length() > 0) {
             tableName_<%=cid%> = <%=dbschema%> + "." + <%=useDifferentTable? differenttable:"\""+dbtable +"\""%>;
        } else {
            tableName_<%=cid%> = <%=useDifferentTable? differenttable:"\""+dbtable +"\""%>;
        }
    <%

    String dataAction = ElementParameterParser.getValue(node,"__DATA_ACTION__");

    List<Map<String, String>> fieldPartitions = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, "__FIELD_PARTITION__");

    String dbhost = null;
    String dbport = null;
    String dbname = null;
    String dbuser = null;
    String hiveVersion = null;
    String distribution = null;

    //hbase settings
       String storeByHBase = null;
    String zookeeperQuorumForHBase = null;
    String zookeeperClientPortForHBase = null;

    boolean setZNodeParent = false;
    String zNodeParent = null;

    String defineRegisterJar = null;
    List<Map<String, String>> registerJarForHBase = null;

    if(previousNode != null) {
        dbhost = ElementParameterParser.getValue(previousNode, "__HOST__");
        dbport = ElementParameterParser.getValue(previousNode, "__PORT__");
        dbname = ElementParameterParser.getValue(previousNode, "__DBNAME__");
        dbuser = ElementParameterParser.getValue(previousNode, "__USER__");
        hiveVersion = ElementParameterParser.getValue(previousNode, "__HIVE_VERSION__");
        distribution = ElementParameterParser.getValue(previousNode, "__DISTRIBUTION__");

        storeByHBase = ElementParameterParser.getValue(previousNode, "__STORE_BY_HBASE__");
        zookeeperQuorumForHBase = ElementParameterParser.getValue(previousNode, "__ZOOKEEPER_QUORUM__");
        zookeeperClientPortForHBase = ElementParameterParser.getValue(previousNode, "__ZOOKEEPER_CLIENT_PORT__");

        setZNodeParent = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_ZNODE_PARENT__"));
        zNodeParent = ElementParameterParser.getValue(previousNode, "__ZNODE_PARENT__");

        defineRegisterJar = ElementParameterParser.getValue(previousNode, "__DEFINE_REGISTER_JAR__");
        registerJarForHBase = (List<Map<String, String>>)ElementParameterParser.getObjectValue(previousNode, "__REGISTER_JAR__");
        isExecutedThroughWebHCat = "MICROSOFT_HD_INSIGHT".equals(ElementParameterParser.getValue(previousNode, "__DISTRIBUTION__"));
        if("true".equals(ElementParameterParser.getValue(previousNode,"__USE_EXISTING_CONNECTION__"))) {
            isExecutedThroughWebHCat = false;
            String connection = ElementParameterParser.getValue(previousNode, "__CONNECTION__");
            for (INode pNode : previousNode.getProcess().getNodesOfType("tHiveConnection")) {
                if(connection!=null && connection.equals(pNode.getUniqueName())) {
                    isExecutedThroughWebHCat = "MICROSOFT_HD_INSIGHT".equals(ElementParameterParser.getValue(pNode, "__DISTRIBUTION__"));
    }
            }
        }
    }

    if(isExecutedThroughWebHCat) {
        INode nodeBackup = node;
        node = previousNode;
%>
        <%@ include file="@{org.talend.designer.components.localprovider}/components/templates/Hive/GetAzureConnection.javajet"%>
<%
        node = nodeBackup;
        if("false".equals(useExistingConn)) { // This variable is declared and initialized in the GetAzureConnection.javajet
            boolean setMemory = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_MEMORY__"));
            if(setMemory) {
                String mapMemory = ElementParameterParser.getValue(previousNode,"__MAPREDUCE_MAP_MEMORY_MB__");
                String reduceMemory = ElementParameterParser.getValue(previousNode,"__MAPREDUCE_REDUCE_MEMORY_MB__");
                String amMemory = ElementParameterParser.getValue(previousNode,"__YARN_APP_MAPREDUCE_AM_RESOURCE_MB__");
%>
                bw_<%=cid%>.write("SET mapreduce.map.memory.mb=" + <%=mapMemory%> + ";");
                bw_<%=cid%>.write("SET mapreduce.reduce.memory.mb=" + <%=reduceMemory%> + ";");
                bw_<%=cid%>.write("SET yarn.app.mapreduce.am.resource.mb=" + <%=amMemory%> + ";");
<%
            }

            List<Map<String, String>> advProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(previousNode, "__ADVANCED_PROPERTIES__");
            if(advProps!=null) {
                for(Map<String, String> item : advProps){
%>
                    bw_<%=cid%>.write("SET "+<%=item.get("PROPERTY")%>+"="+<%=item.get("VALUE")%> + ";");
<%
                }
            }
%>
            String dbname_<%=cid%> = <%=dbname%>;
            if(dbname_<%=cid%>!=null && !"".equals(dbname_<%=cid%>.trim()) && !"default".equals(dbname_<%=cid%>.trim())) {
                bw_<%=cid%>.write("use " + dbname_<%=cid%> + ";");
            }
<%
        }
    } else {
        boolean useExistingConn = ("true").equals(ElementParameterParser.getValue(previousNode, "__USE_EXISTING_CONNECTION__"));
%>
java.sql.Connection conn_<%=cid%> = null;

<%
        connectionMode = ElementParameterParser.getValue(previousNode, "__CONNECTION_MODE__");
        setFsDefaultName = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_FS_DEFAULT_NAME__"));
        fsDefaultName = ElementParameterParser.getValue(previousNode, "__FS_DEFAULT_NAME__");

String yarnClasspathSeparator = ElementParameterParser.getValue(previousNode, "__CLASSPATH_SEPARATOR__");
%>
globalMap.put("current_client_path_separator", System.getProperty("path.separator"));
System.setProperty("path.separator", <%=yarnClasspathSeparator%>);
<%

if(useExistingConn) {
     connectionMode = "";
     setFsDefaultName = false;
     fsDefaultName = "";
     dbuser = "";
     hiveVersion = "";
     distribution = "";
    String connection = ElementParameterParser.getValue(previousNode, "__CONNECTION__");
    for (INode pNode : node.getProcess().getNodesOfType("tHiveConnection")) {
            if(connection!=null && connection.equals(pNode.getUniqueName())) {
                connectionMode = ElementParameterParser.getValue(pNode, "__CONNECTION_MODE__");
                setFsDefaultName = "true".equals(ElementParameterParser.getValue(pNode, "__SET_FS_DEFAULT_NAME__"));
                fsDefaultName = ElementParameterParser.getValue(pNode, "__FS_DEFAULT_NAME__");
                dbuser = ElementParameterParser.getValue(pNode, "__USER__");
                hiveVersion = ElementParameterParser.getValue(pNode, "__HIVE_VERSION__");
                distribution = ElementParameterParser.getValue(pNode, "__DISTRIBUTION__");
                break;
            }
     }

    String conn = "conn_" + connection;
    String db = "db_" + connection;
    String dbUser = "dbUser_" + connection;
    %>
    conn_<%=cid%> = (java.sql.Connection)globalMap.get("<%=conn%>");

    String dbname_<%=cid%> = (String)globalMap.get("<%=db%>");
    if(dbname_<%=cid%>!=null && !"".equals(dbname_<%=cid%>.trim()) && !"default".equals(dbname_<%=cid%>.trim())) {
        java.sql.Statement goToDatabase_<%=cid%> = conn_<%=cid%>.createStatement();
        goToDatabase_<%=cid%>.execute("use " + dbname_<%=cid%>);
        goToDatabase_<%=cid%>.close();
    }

    String dbUser_<%=cid%> = (String)globalMap.get("<%=dbUser%>");


    globalMap.put("HADOOP_USER_NAME_<%=cid%>", System.getProperty("HADOOP_USER_NAME"));
    if(dbUser_<%=cid %>!=null && !"".equals(dbUser_<%=cid %>.trim())) {
        System.setProperty("HADOOP_USER_NAME",dbUser_<%=cid %>);
        //make relative file path work for hive
        globalMap.put("current_client_user_name", System.getProperty("user.name"));
        System.setProperty("user.name",dbUser_<%=cid %>);
    }
    <%
} else {
        String javaDbDriver = "org.apache.hadoop.hive.jdbc.HiveDriver";
        String hiveServer = ElementParameterParser.getValue(previousNode, "__HIVE_SERVER__");

        boolean isCustom = "CUSTOM".equals(ElementParameterParser.getValue(previousNode, "__DISTRIBUTION__"));

        boolean useKrb = "true".equals(ElementParameterParser.getValue(previousNode, "__USE_KRB__"));
        boolean cdhCanBeSecured = ("Cloudera_CDH4".equals(hiveVersion) || "Cloudera_CDH4_YARN".equals(hiveVersion) || "Cloudera_CDH5".equals(hiveVersion) || "Cloudera_CDH5_1".equals(hiveVersion) || "Cloudera_CDH5_1_MR1".equals(hiveVersion)) && (("HIVE".equalsIgnoreCase(hiveServer) && "EMBEDDED".equalsIgnoreCase(connectionMode)) || "HIVE2".equalsIgnoreCase(hiveServer));
        boolean pivotalCanBeSecured = ("PIVOTAL_HD_2_0".equals(hiveVersion)) && (("HIVE".equalsIgnoreCase(hiveServer) && "EMBEDDED".equalsIgnoreCase(connectionMode)) || "HIVE2".equalsIgnoreCase(hiveServer));
        boolean securityIsEnabled = useKrb && (isCustom || ("HDP_1_0".equals(hiveVersion) || "HDP_1_2".equals(hiveVersion) || "HDP_1_3".equals(hiveVersion) || "HDP_2_0".equals(hiveVersion) || "HDP_2_1".equals(hiveVersion) || "HDP_2_2".equals(hiveVersion) || cdhCanBeSecured || pivotalCanBeSecured));

        boolean securedStandaloneHive2 = securityIsEnabled && "HIVE2".equalsIgnoreCase(hiveServer) && "STANDALONE".equalsIgnoreCase(connectionMode);
        boolean securedEmbedded = securityIsEnabled && "EMBEDDED".equalsIgnoreCase(connectionMode);
        String hivePrincipal = ElementParameterParser.getValue(previousNode, "__HIVE_PRINCIPAL__");

        if(hiveServer!=null && !"".equals(hiveServer.trim()) && (isCustom || "HDP_1_2".equals(hiveVersion) || "HDP_1_3".equals(hiveVersion) || "Cloudera_CDH4".equals(hiveVersion) || "Cloudera_CDH4_YARN".equals(hiveVersion) || "Cloudera_CDH5".equals(hiveVersion) || "Cloudera_CDH5_1".equals(hiveVersion) || "Cloudera_CDH5_1_MR1".equals(hiveVersion) || "MAPR213".equals(hiveVersion) || "MAPR301".equals(hiveVersion) || "MAPR310".equals(hiveVersion) || "MAPR401".equals(hiveVersion) || "HDP_2_0".equals(hiveVersion) || "HDP_2_1".equals(hiveVersion) || "HDP_2_2".equals(hiveVersion) || "PIVOTAL_HD_2_0".equals(hiveVersion))) {
            hiveServer = hiveServer.toLowerCase();
            if ("hive2".equals(hiveServer)) {
                javaDbDriver = "org.apache.hive.jdbc.HiveDriver";
            }
        } else {
            hiveServer = "hive";
        }

        if(!isCustom && (("HDP_1_0".equals(hiveVersion) && "STANDALONE".equals(connectionMode)) || ("HDP_1_2".equals(hiveVersion) && "STANDALONE".equals(connectionMode) && "HIVE".equalsIgnoreCase(hiveServer))
         || ("HDP_1_3".equals(hiveVersion) && "STANDALONE".equals(connectionMode) && "HIVE".equalsIgnoreCase(hiveServer)) || ("HDP_2_0".equals(hiveVersion) && "STANDALONE".equals(connectionMode) && "HIVE".equalsIgnoreCase(hiveServer))
          || ("HDP_2_1".equals(hiveVersion) && "STANDALONE".equals(connectionMode) && "HIVE".equalsIgnoreCase(hiveServer)) || ("HDP_2_2".equals(hiveVersion) && "STANDALONE".equals(connectionMode) && "HIVE".equalsIgnoreCase(hiveServer)) || ("APACHE_0_20_203".equals(hiveVersion) && "EMBEDDED".equals(connectionMode)) || ("MAPR1".equals(hiveVersion) && "EMBEDDED".equals(connectionMode))
           || ("MapR_EMR".equals(hiveVersion) && "EMBEDDED".equals(connectionMode)) || ("Cloudera_CDH3".equals(hiveVersion) && "EMBEDDED".equals(connectionMode)))) {
%>
            if(true) {
                throw new Exception("The Hive version and the connection mode are not compatible together. Please check your component configuration.");
            }
<%
        }
%>
        String dbUser_<%=cid %> = <%=dbuser%>;

        <%
        String passwordFieldName = "__PASS__";
        %>

        <%@ include file="@{org.talend.designer.components.localprovider}/components/templates/eltpassword.javajet"%>

        String dbPwd_<%=cid %> = decryptedPassword_<%=cid%>;

        <%
        boolean setHadoopUser = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_HADOOP_USER__"));
        if (setHadoopUser) {
            String hadoopUser = ElementParameterParser.getValue(previousNode, "__HADOOP_USER__");
            %>
            String username_<%=cid %> = <%=hadoopUser%>;
            if(username_<%=cid %>!=null && !"".equals(username_<%=cid %>.trim())) {
                System.setProperty("HADOOP_USER_NAME",username_<%=cid %>);
            }
            <%
        }
        %>

        globalMap.put("HADOOP_USER_NAME_<%=cid%>", System.getProperty("HADOOP_USER_NAME"));
<%
        if("EMBEDDED".equals(connectionMode)) {
%>
            System.setProperty("hive.metastore.local", "false");
            System.setProperty("hive.metastore.uris", "thrift://" + <%=dbhost%> + ":" + <%=dbport%>);
            System.setProperty("hive.metastore.execute.setugi", "true");
            String url_<%=cid%> = "jdbc:<%=hiveServer%>://";
<%
            if(isCustom || (!isCustom && ("HDP_1_0,HDP_1_2,HDP_1_3,HDP_2_0,HDP_2_1,HDP_2_2,Cloudera_CDH4,Cloudera_CDH4_YARN,Cloudera_CDH5,Cloudera_CDH5_1,Cloudera_CDH5_1_MR1,PIVOTAL_HD_1_0_1,PIVOTAL_HD_2_0".contains(hiveVersion)))) {
%>
                if(dbUser_<%=cid %>!=null && !"".equals(dbUser_<%=cid %>.trim())) {
                    System.setProperty("HADOOP_USER_NAME",dbUser_<%=cid %>);
                    //make relative file path work for hive
                    globalMap.put("current_client_user_name", System.getProperty("user.name"));
                    System.setProperty("user.name",dbUser_<%=cid %>);
                }
<%
            }
        } else {
            if(securedStandaloneHive2) {
%>
                String url_<%=cid%> = "jdbc:<%=hiveServer%>://" + <%=dbhost%> + ":" + <%=dbport%> + "/" + <%=dbname%> + ";principal=" + <%=hivePrincipal%>;
<%
            } else {
%>
                String url_<%=cid%> = "jdbc:<%=hiveServer%>://" + <%=dbhost%> + ":" + <%=dbport%> + "/" + <%=dbname%>;
<%
            }
        }
%>
        java.lang.Class.forName("<%=javaDbDriver %>");
<%
        if(securedStandaloneHive2) {
%>
            conn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid %>);
<%
        } else {
%>
            conn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid %>, dbUser_<%=cid%>, dbPwd_<%=cid%>);
<%
        }

%>
        java.sql.Statement init_<%=cid%> = conn_<%=cid%>.createStatement();
<%
        if(!isCustom && ("HDP_1_2".equals(hiveVersion) || "HDP_1_3".equals(hiveVersion))) {
            String mapMemory = ElementParameterParser.getValue(previousNode,"__MAPRED_JOB_MAP_MEMORY_MB__");
            String reduceMemory = ElementParameterParser.getValue(previousNode,"__MAPRED_JOB_REDUCE_MEMORY_MB__");
%>
            init_<%=cid%>.execute("SET mapred.job.map.memory.mb=" + <%=mapMemory%>);
            init_<%=cid%>.execute("SET mapred.job.reduce.memory.mb=" + <%=reduceMemory%>);
<%
        }

        boolean isKerberosAvailableHadoop2 = !isCustom && ("HDP_2_0".equals(hiveVersion) || "HDP_2_1".equals(hiveVersion) || "HDP_2_2".equals(hiveVersion) || "Cloudera_CDH4_YARN".equals(hiveVersion) || "Cloudera_CDH5".equals(hiveVersion) || "Cloudera_CDH5_1".equals(hiveVersion) || "PIVOTAL_HD_2_0".equals(hiveVersion));
        boolean isHadoop2 = "PIVOTAL_HD_1_0_1".equals(hiveVersion) || "APACHE_2_4_0_EMR".equals(hiveVersion) || "MAPR401".equals(hiveVersion) ||  isKerberosAvailableHadoop2;

        boolean isKerberosAvailableHadoop1 = !isCustom && ("HDP_1_0".equals(hiveVersion) || "HDP_1_2".equals(hiveVersion) || "HDP_1_3".equals(hiveVersion) || "Cloudera_CDH4".equals(hiveVersion) || "Cloudera_CDH5_1_MR1".equals(hiveVersion));

        boolean useYarn = "true".equals(ElementParameterParser.getValue(previousNode, "__USE_YARN__"));

        if(securedEmbedded) {
            String namenodePrincipal = ElementParameterParser.getValue(previousNode, "__NAMENODE_PRINCIPAL__");
%>
            init_<%=cid%>.execute("SET dfs.namenode.kerberos.principal=" + <%=namenodePrincipal%>);
<%
            if(isKerberosAvailableHadoop1 || (isCustom && !useYarn)) {
                String jobtrackerPrincipal = ElementParameterParser.getValue(previousNode, "__JOBTRACKER_PRINCIPAL__");
%>
                init_<%=cid%>.execute("SET mapreduce.jobtracker.kerberos.principal=" + <%=jobtrackerPrincipal%>);
<%
            }
            if(isKerberosAvailableHadoop2 || (isCustom && useYarn)) {
                String resourceManagerPrincipal = ElementParameterParser.getValue(previousNode, "__RESOURCEMANAGER_PRINCIPAL__");
%>
                init_<%=cid%>.execute("SET yarn.resourcemanager.principal=" + <%=resourceManagerPrincipal%>);
<%
            }

        }

        boolean setResourceManager = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_RESOURCE_MANAGER__"));

        if((isCustom && useYarn) || (!isCustom && isHadoop2)) {
            if(setResourceManager) {
                String resourceManager = ElementParameterParser.getValue(previousNode, "__RESOURCE_MANAGER__");
%>
                init_<%=cid%>.execute("SET mapreduce.framework.name=yarn");
                init_<%=cid%>.execute("SET yarn.resourcemanager.address=" + <%=resourceManager%>);
<%
            }

            boolean setJobHistoryAddress = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_JOBHISTORY_ADDRESS__"));
            if(setJobHistoryAddress) {
                String jobHistoryAddress = ElementParameterParser.getValue(previousNode,"__JOBHISTORY_ADDRESS__");
                %>
                init_<%=cid%>.execute("SET mapreduce.jobhistory.address=" + <%=jobHistoryAddress%>);
                <%
            }

            boolean setSchedulerAddress = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_SCHEDULER_ADDRESS__"));
            if(setSchedulerAddress) {
                String schedulerAddress = ElementParameterParser.getValue(previousNode,"__RESOURCEMANAGER_SCHEDULER_ADDRESS__");
%>
                init_<%=cid%>.execute("SET yarn.resourcemanager.scheduler.address=" + <%=schedulerAddress%>);
<%
            }

            if(setFsDefaultName) {
%>
                init_<%=cid%>.execute("SET fs.default.name=" + <%=fsDefaultName%>);
<%
            }

            if("EMBEDDED".equals(connectionMode)) {
                if(!isCustom && ("HDP_2_1".equals(hiveVersion) || "HDP_2_2".equals(hiveVersion) || "Cloudera_CDH5".equals(hiveVersion) || "Cloudera_CDH5_1".equals(hiveVersion) || "MAPR401".equals(hiveVersion))) {
%>
                init_<%=cid%>.execute("SET mapreduce.app-submission.cross-platform=true");
<%
                }

                if(!isCustom && "HDP_2_1".equals(hiveVersion)) {
%>
                init_<%=cid%>.execute("SET yarn.application.classpath=/etc/hadoop/conf,/usr/lib/hadoop/*,/usr/lib/hadoop/lib/*,/usr/lib/hadoop-hdfs/*,/usr/lib/hadoop-hdfs/lib/*,/usr/lib/hadoop-yarn/*,/usr/lib/hadoop-yarn/lib/*,/usr/lib/hadoop-mapreduce/*,/usr/lib/hadoop-mapreduce/lib/*");
<%
                /**/
                } else if(!isCustom && "HDP_2_2".equals(hiveVersion)) {
%>
				init_<%=cid%>.execute("SET mapreduce.application.classpath=$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/etc/hadoop/conf/secure");
				init_<%=cid%>.execute("SET yarn.application.classpath=$HADOOP_CONF_DIR,/usr/hdp/current/hadoop-client/*,/usr/hdp/current/hadoop-client/lib/*,/usr/hdp/current/hadoop-hdfs-client/*,/usr/hdp/current/hadoop-hdfs-client/lib/*,/usr/hdp/current/hadoop-mapreduce-client/*,/usr/hdp/current/hadoop-mapreduce-client/lib/*,/usr/hdp/current/hadoop-yarn-client/*,/usr/hdp/current/hadoop-yarn-client/lib/*");
<%
				} else if(!isCustom && "APACHE_2_4_0_EMR".equals(hiveVersion)) {
                    %>
                    init_<%=cid%>.execute("SET yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*,/usr/share/aws/emr/emr-fs/lib/*,/usr/share/aws/emr/lib/*,/home/hadoop/hive/conf/*");
//                    init_<%=cid%>.execute("SET yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$YARN_HOME/*,$YARN_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*");
                    <%
                } else {
%>
                //set default yarn classpath with environment variable
                init_<%=cid%>.execute("SET yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$YARN_HOME/*,$YARN_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$HADOOP_COMMON_HOME/share/hadoop/common/*,$HADOOP_COMMON_HOME/share/hadoop/common/lib/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/*,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*,$HADOOP_YARN_HOME/share/hadoop/yarn/*,$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*");
<%
                /**/
                }

                if ("true".equals(ElementParameterParser.getValue(previousNode, "__USE_DATANODE_HOSTNAME__"))) {
                    %>
                    init_<%=cid%>.execute("SET dfs.client.use.datanode.hostname=true");
                    <%
                }

                boolean crossPlatformSubmission = "true".equals(ElementParameterParser.getValue(previousNode, "__CROSS_PLATFORM_SUBMISSION__"));
                if(isCustom && useYarn && crossPlatformSubmission) {
%>
                init_<%=cid%>.execute("SET mapreduce.app-submission.cross-platform=true");
<%
                }
            }

            boolean setMemory = "true".equals(ElementParameterParser.getValue(previousNode, "__SET_MEMORY__"));
            if(setMemory) {
                String mapMemory = ElementParameterParser.getValue(previousNode,"__MAPREDUCE_MAP_MEMORY_MB__");
                String reduceMemory = ElementParameterParser.getValue(previousNode,"__MAPREDUCE_REDUCE_MEMORY_MB__");
                String amMemory = ElementParameterParser.getValue(previousNode,"__YARN_APP_MAPREDUCE_AM_RESOURCE_MB__");
%>
                init_<%=cid%>.execute("SET mapreduce.map.memory.mb=" + <%=mapMemory%>);
                init_<%=cid%>.execute("SET mapreduce.reduce.memory.mb=" + <%=reduceMemory%>);
                init_<%=cid%>.execute("SET yarn.app.mapreduce.am.resource.mb=" + <%=amMemory%>);
<%
            }
        }

        List<Map<String, String>> advProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(previousNode, "__ADVANCED_PROPERTIES__");
        if(advProps!=null) {
            for(Map<String, String> item : advProps){
%>
                init_<%=cid%>.execute("SET "+<%=item.get("PROPERTY")%>+"="+<%=item.get("VALUE")%>);
<%
            }
        }
%>
        init_<%=cid%>.close();

        String dbname_<%=cid%> = <%=dbname%>;
        if(dbname_<%=cid%>!=null && !"".equals(dbname_<%=cid%>.trim()) && !"default".equals(dbname_<%=cid%>.trim())) {
            java.sql.Statement goToDatabase_<%=cid%> = conn_<%=cid%>.createStatement();
            goToDatabase_<%=cid%>.execute("use " + dbname_<%=cid%>);
            goToDatabase_<%=cid%>.close();
        }
<%
        if("true".equalsIgnoreCase(storeByHBase) && !("EMBEDDED".equals(connectionMode) && "MAPR2".equals(hiveVersion))) {%>
            java.sql.Statement statement_<%=cid%> = conn_<%=cid%>.createStatement();
            <%if(zookeeperQuorumForHBase!=null && !"".equals(zookeeperQuorumForHBase) && !"\"\"".equals(zookeeperQuorumForHBase)) {%>
                statement_<%=cid%>.execute("SET hbase.zookeeper.quorum="+<%=zookeeperQuorumForHBase%>);
            <%}%>

            <%if(zookeeperClientPortForHBase!=null && !"".equals(zookeeperClientPortForHBase) && !"\"\"".equals(zookeeperClientPortForHBase)) {%>
                statement_<%=cid%>.execute("SET hbase.zookeeper.property.clientPort="+<%=zookeeperClientPortForHBase%>);
            <%}%>

            <%if(setZNodeParent && zNodeParent!=null && !"".equals(zNodeParent) && !"\"\"".equals(zNodeParent)) {%>
                statement_<%=cid%>.execute("SET zookeeper.znode.parent="+<%=zNodeParent%>);
            <%}%>

            <%if("true".equalsIgnoreCase(defineRegisterJar) && registerJarForHBase!=null && registerJarForHBase.size()>0) {
                for(Map<String, String> jar : registerJarForHBase){
                    String path = jar.get("JAR_PATH");
                    if(path == null || "".equals(path) || "\"\"".equals(path)) {
                        continue;
                    }
            %>
                    statement_<%=cid%>.execute("add jar "+<%=path%>);
            <%
                }
                }
%>
            statement_<%=cid%>.close();
<%
            }
  }
 }

 List<IMetadataColumn> columnList = null;

 List<IMetadataTable> metadatas = node.getMetadataList();
 if(metadatas !=null && metadatas.size()>0){
     IMetadataTable metadata = metadatas.get(0);
     if(metadata != null){
         columnList = metadata.getListColumns();
     }
}

    // Register jars to handle the parquet format.
    boolean targetTableUsesParquetFormat = "true".equals(ElementParameterParser.getValue(node, "__TARGET_TABLE_IS_A_PARQUET_TABLE__"));

    java.util.List<String> hiveVersionList = new java.util.ArrayList<String>();
    hiveVersionList.add("APACHE_0_20_203");
    hiveVersionList.add("Cloudera_CDH3");
    hiveVersionList.add("Cloudera_CDH4");
    hiveVersionList.add("APACHE_1_0_0");
    hiveVersionList.add("MAPR2");
    hiveVersionList.add("HDP_1_0");
    hiveVersionList.add("PIVOTAL_HD_1_0_1");

    boolean isParquetSupported = "CUSTOM".equals(distribution) || !hiveVersionList.contains(hiveVersion);
    if(targetTableUsesParquetFormat && !isParquetSupported) {
%>
        if(true) {
            throw new java.lang.UnsupportedOperationException("Parquet is only supported if the distribution uses embedded Hive version 0.10 or later.");
        }
<%
    }

    boolean generateAddJarCodeForAll = targetTableUsesParquetFormat;

    if(targetTableUsesParquetFormat) {
        String compression = ElementParameterParser.getValue(node, "__PARQUET_COMPRESSION__");
        java.util.List<String> jarsToRegister = null;
        java.util.List<String> jars = null;
        if(generateAddJarCodeForAll) {
            String[] commandLine = new String[] {"<command>"};
            try {
                commandLine = ProcessorUtilities.getCommandLine("win32",true, processId, "",org.talend.designer.runprocess.IProcessor.NO_STATISTICS,org.talend.designer.runprocess.IProcessor.NO_TRACES, new String[]{});
            } catch (ProcessorException e) {
                e.printStackTrace();
            }

            jarsToRegister = new java.util.ArrayList();

            jarsToRegister.add("snappy-java");
            jarsToRegister.add("parquet-hive-bundle");

            for (int j = 0; j < commandLine.length; j++) {
                if(commandLine[j].contains("jar")) {
                    jars = java.util.Arrays.asList(commandLine[j].split(";"));
                    break;
                }
            }
        }
        if(jarsToRegister!=null && jars!=null) {
            if("EMBEDDED".equalsIgnoreCase(connectionMode) || isExecutedThroughWebHCat) {
%>
                <%@ include file="@{org.talend.designer.components.localprovider}/components/templates/GetJarsToRegister.javajet"%>
                GetJarsToRegister_<%=cid%> getJarsToRegister_<%=cid %> = new GetJarsToRegister_<%=cid%>();
<%
            } else {
                generateAddJarCodeForAll = false;
                if(setFsDefaultName) {
                    generateAddJarCodeForAll = true;
%>
                    <%@ include file="@{org.talend.designer.components.localprovider}/components/templates/Hive/GetHiveJarsToRegister.javajet"%>
                    GetHiveJarsToRegister_<%=cid%> getJarsToRegister_<%=cid %> = new GetHiveJarsToRegister_<%=cid%>();
<%
                }
            }

            if(generateAddJarCodeForAll) {
                if(!isExecutedThroughWebHCat) { // Then we create a SQL statement to add the jars.
%>
                java.sql.Statement addJar_<%=cid%> = null;
<%
                }
                for(int i=0; i<jarsToRegister.size(); i++) {
                    String jarToRegister = jarsToRegister.get(i);
                    for(int j=0; j<jars.size(); j++) {
                        if(jars.get(j).contains(jarToRegister)) {
                            if(!isExecutedThroughWebHCat) { // Then we use the created SQL statement to add the jars.
%>
                            addJar_<%=cid%> = conn_<%=cid%>.createStatement();
                            try {
                                addJar_<%=cid%>.execute("add jar " + getJarsToRegister_<%=cid %>.replaceJarPaths("<%=jars.get(j)%>"));
                            } catch (Exception e) {
                                e.printStackTrace();
                            } finally {
                                addJar_<%=cid%>.close();
                            }
<%
                            } else {
%>
                                bw_<%=cid%>.write("ADD JAR " + wasbPath_<%=cid%> + new java.io.File(getJarsToRegister_<%=cid %>.replaceJarPaths("<%=jars.get(j)%>")).getName() + ";");
                                libjars_<%=cid%>.append(getJarsToRegister_<%=cid %>.replaceJarPaths("<%=jars.get(j)%>") + ",");
<%
                            }
                        }
                    }
                }
            }
        }

        if(!isExecutedThroughWebHCat) {
%>
            java.sql.Statement setCompression_<%=cid%> = conn_<%=cid%>.createStatement();
            try {
                setCompression_<%=cid%>.execute("SET parquet.compression=<%=compression%>");
            } finally {
                setCompression_<%=cid%>.close();
            }
<%
        } else {
%>
            bw_<%=cid%>.write("SET parquet.compression=<%=compression%>;");
<%
        }
    }
        // End of parquet format handling.
%>
<%
    if(!isExecutedThroughWebHCat) {
%>
        java.sql.Statement stmt_<%=cid %> = conn_<%=cid %>.createStatement();
<%
    }
%>
    StringBuffer partitionSql = new StringBuffer();
    String startPartition = "";
    String endPartition = "";
    String bodyPartition = "";
<%
    //For Bug TDI-24105,support context variables
    if(fieldPartitions != null && !fieldPartitions.isEmpty()) {
        String columnName = null;
        String columnValue = null;
        int count = 0 ;
%>
    startPartition = " PARTITION(";
    endPartition = ")";
<%
        for(Map<String, String> line : fieldPartitions ) {// search in the configuration table
             columnName = line.get("COLUMN_NAME");
             columnValue = line.get("COLUMN_VALUE");
            if (columnName!=null && !"".equals(columnName)) {
                count++;
%>
                bodyPartition = bodyPartition + <%=columnName%>;
<%
                   if (columnValue!=null && !"".equals(columnValue)) {
%>
                       bodyPartition = bodyPartition + "=";
                       bodyPartition = bodyPartition + <%=columnValue%>;
<%
                }
                if(count < fieldPartitions.size()){
%>
                    bodyPartition = bodyPartition + ",";
<%
                }
            }
        }
    }
%>
    partitionSql.append(startPartition).append(bodyPartition).append(endPartition);

<%

if(columnList != null && columnList.size()>0){
    if(("INSERT").equals(dataAction)){
%>
    String insertQuery_<%=cid %> = "INSERT INTO TABLE "+tableName_<%=cid%> + partitionSql.toString() + " "+select_query_<%=cid %>;
<%
            if(!isExecutedThroughWebHCat) {
%>
    stmt_<%=cid %>.execute(insertQuery_<%=cid %>);
<%
            } else {
%>
                bw_<%=cid%>.write(insertQuery_<%=cid %> + ";");
<%
            }
%>
<%
    }else if (("OVERWRITE").equals(dataAction)){
%>
    String overwriteQuery_<%=cid %> = "INSERT OVERWRITE TABLE "+tableName_<%=cid%>+ partitionSql.toString() + " "+select_query_<%=cid %>;
<%
            if(!isExecutedThroughWebHCat) {
%>
    stmt_<%=cid %>.execute(overwriteQuery_<%=cid %>);

<%
            } else {
%>
                bw_<%=cid%>.write(overwriteQuery_<%=cid %> + ";");
<%
            }
    }
}

// END

    boolean useExistingConn = ("true").equals(ElementParameterParser.getValue(previousNode, "__USE_EXISTING_CONNECTION__"));

    if(!isExecutedThroughWebHCat) {
%>
stmt_<%=cid %>.close();

<%
if(!useExistingConn) {
    %>
    if(conn_<%=cid%> != null && !conn_<%=cid%>.isClosed()) {
        conn_<%=cid%> .close();
    }
    <%
}
%>

String currentClientPathSeparator_<%=cid%> = (String)globalMap.get("current_client_path_separator");
if(currentClientPathSeparator_<%=cid%>!=null) {
    System.setProperty("path.separator", currentClientPathSeparator_<%=cid%>);
    globalMap.put("current_client_path_separator", null);
}

String currentClientUsername_<%=cid%> = (String)globalMap.get("current_client_user_name");
if(currentClientUsername_<%=cid%>!=null) {
    System.setProperty("user.name", currentClientUsername_<%=cid%>);
    globalMap.put("current_client_user_name", null);
}

String originalHadoopUsername_<%=cid%> = (String)globalMap.get("HADOOP_USER_NAME_<%=cid%>");
if(originalHadoopUsername_<%=cid%>!=null) {
    System.setProperty("HADOOP_USER_NAME", originalHadoopUsername_<%=cid%>);
    globalMap.put("HADOOP_USER_NAME_<%=cid%>", null);
} else {
    System.clearProperty("HADOOP_USER_NAME");
}
<%
    } else {
%>
        bw_<%=cid%>.close();

        if(libjars_<%=cid%>.length() > 0) {
            instance_<%=cid%>.setLibJars(libjars_<%=cid%>.toString().substring(0, libjars_<%=cid%>.length()-1));
        }

        instance_<%=cid%>.sendFiles();
        instance_<%=cid%>.callWS(null, true);
        int exitCode_<%=cid%> = instance_<%=cid%>.execute();
        if(exitCode_<%=cid%> > 0) {
            throw new Exception("The Hive job failed. Please read the logs for more details");
        }
<%
    }
%>
